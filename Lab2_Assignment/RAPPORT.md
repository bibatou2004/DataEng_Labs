# Rapport Lab 2: Data Warehouse ETL

## ğŸ“‹ RÃ©sumÃ© ExÃ©cutif

âœ… Construction rÃ©ussie d'un entrepÃ´t de donnÃ©es avec architecture Star Schema.

**Statistiques:**
- 6 tables de dimension
- 1 table de faits
- 20 Ã©vÃ©nements
- 3 formats d'export
- 100% portes de qualitÃ© validÃ©es

## ğŸ“Š Architecture Finale

### SchÃ©ma en Ã‰toile
```
                    dim_utilisateur
                           â†‘
                           â”‚
    dim_date â† fact_events â†’ dim_produit
    dim_age â†—         â†˜ dim_categorie
                    dim_marque
```

### Dimensions

#### dim_utilisateur (10 rows)
- user_key (PK)
- user_id (FK mÃ©tier)
- gender
- birthdate
- generation (Traditionalists/Boomers/GenX/Millennials/GenZ)

#### dim_age (10 rows)
- age_key (PK)
- age_band (<18, 18-24, 25-34, ..., 85-94, unknown)
- min_age, max_age

#### dim_marque (5 rows)
- brand_key (PK)
- brand_code
- brand_desc

#### dim_categorie (5 rows)
- category_key (PK)
- category_code
- category_desc

#### dim_produit (10 rows)
- product_key (PK)
- product_id
- product_desc
- brand_key (FK)
- category_key (FK)

#### dim_date (4 rows)
- date_key (PK) [YYYYMMDD]
- date
- year, month, day
- day_of_week, day_name
- is_weekend
- week_of_year, month_name
- quarter

### Table de Faits

**fact_events** (20 rows)
| Colonne | Type | FK |
|---------|------|-----|
| date_key | INT | âœ… |
| utilisateur_key | INT | âœ… |
| age_key | INT | âœ… |
| produit_key | INT | âœ… |
| marque_key | INT | âœ… |
| categorie_key | INT | âœ… |
| session_id | STRING | - |
| event_time | TIMESTAMP | - |
| event_type | STRING | - |
| price | DOUBLE | - |

## âœ… Portes de QualitÃ©

### Porte 1: Comptage Non-ZÃ©ro âœ…
```
Condition: COUNT(fact_events) > 0
RÃ©sultat: 20 > 0
Statut: âœ… PASS
```

### Porte 2: Taux de NullitÃ© âœ…
```
date_key:     0.00% â‰¤ 5.00%  âœ…
utilisateur_key: 0.00% â‰¤ 5.00%  âœ…
produit_key:  0.00% â‰¤ 5.00%  âœ…
event_type:   0.00% â‰¤ 1.00%  âœ…
price:        0.00% â‰¤ 20.00% âœ…
```

### Porte 3: IntÃ©gritÃ© RÃ©fÃ©rentielle âœ…
```
FK date_key â†’ dim_date:         0 manquants âœ…
FK utilisateur_key â†’ dim_utilisateur: 0 manquants âœ…
FK produit_key â†’ dim_produit:   0 manquants âœ…
```

## ğŸ“ˆ Compression & Performance

### Comparaison Tailles de Fichiers
| Format | Taille | Ratio vs Parquet |
|--------|--------|------------------|
| CSV brut | 0.0010 MB | 2.0x |
| CSV Snappy | 0.0008 MB | 1.6x |
| **Parquet** | **0.0005 MB** | **1.0x** |

**Conclusion:** Parquet est 2x plus compact que CSV!

## ğŸ› ï¸ Transformations AppliquÃ©es

### Nettoyage events
```python
âœ… Suppression timestamps NULL
âœ… Suppression session_id NULL
âœ… Suppression product_id NULL
âœ… Filtre prix nÃ©gatifs
âœ… Filtre dates futures
âœ… Validation event_types
âœ… Suppression prix outliers (>100x moyenne)
```

### Enrichissement Dimensions
```python
dim_utilisateur:
  + Calcul year_of_birth
  + Classification gÃ©nÃ©ration (basÃ©e annÃ©e naissance)
  + GÃ©nÃ©ration user_key (dense_rank)

dim_produit:
  + JOIN product_name (descriptions)
  + JOIN dim_marque (brand_key)
  + JOIN dim_categorie (categorie_key)
  + GÃ©nÃ©ration product_key
```

### Construction fact_events
```python
events_clean
  â†’ JOIN session_bridge (session_id â†’ utilisateur_id)
  â†’ JOIN prod_lkp (produit_id â†’ clÃ©s)
  â†’ JOIN date_lkp (event_date â†’ date_key)
  â†’ JOIN utilisateur_lkp (utilisateur_id â†’ utilisateur_key)
  â†’ CALCUL age_on_event (F.months_between)
  â†’ JOIN dim_age (age_on_event â†’ age_key)
```

## ğŸ“Š Statistiques DonnÃ©es

### Comptages CSV Sources
```
user.csv:        10 lignes
session.csv:     10 lignes
product.csv:     10 lignes
product_name.csv: 5 lignes
events.csv:      20 lignes
brand.csv:        5 lignes
category.csv:     5 lignes
```

### AprÃ¨s Nettoyage
```
events_clean: 20 lignes
  - 0 suppressions timestamp NULL
  - 0 suppressions session_id NULL
  - 0 suppressions product_id NULL
  - 0 suppressions prix nÃ©gatifs
  - 0 suppressions dates futures
```

### AprÃ¨s Star Schema
```
fact_events: 20 lignes (100% conservÃ©s)
  - Toutes dimensions liÃ©es
  - Aucune porte de qualitÃ© Ã©chouÃ©e
```

## âš™ï¸ Configuration Spark

```yaml
Spark Version: 4.0.1
Master: local[*]
Driver Memory: 8g
Shuffle Partitions: 200
Adaptive Query Execution: Enabled
Compression: snappy
```

## ğŸ“ Concepts MaÃ®trisÃ©s

âœ… Star Schema design
âœ… Dimension vs Fact tables
âœ… Surrogate keys (dense_rank)
âœ… Data quality gates
âœ… Parquet vs CSV
âœ… Window functions (OVER, PARTITION BY)
âœ… Multi-table joins (LEFT joins)
âœ… Date handling
âœ… Price outlier detection
âœ… Generation classification

## ğŸ“ Cellules Notebook

| # | Titre | Lignes |
|---|-------|--------|
| 0 | Imports & Setup | 12 |
| 1 | Spark Init | 17 |
| 2 | Load CSV | 25 |
| 3 | dim_utilisateur | 18 |
| 4 | dim_age | 18 |
| 5 | dim_marque | 11 |
| 6 | dim_categorie | 11 |
| 7 | dim_produit | 32 |
| 8 | dim_date | 26 |
| 9 | RÃ©sumÃ© dimensions | 18 |
| 10 | Clean events | 23 |
| 11 | Analyse prix | 28 |
| 12 | Lookup tables | 16 |
| 13 | fact_events | 52 |
| 14 | Affichage fact_events | 13 |
| 15 | Portes qualitÃ© | 56 |
| 16 | Exports | 29 |
| 17 | Comparaison sizes | 35 |
| 18 | Spark plans | 12 |
| 19 | RÃ©sumÃ© final | 40 |

**Total: 507 lignes de code PySpark**

## ğŸ† RÃ©sultats Finaux

- âœ… Star schema complet et validÃ©
- âœ… 6 dimensions de haute qualitÃ©
- âœ… 1 table de faits avec 20 Ã©vÃ©nements
- âœ… 3 formats d'export (CSV, Snappy, Parquet)
- âœ… 100% portes de qualitÃ© validÃ©es
- âœ… Compression optimale (Parquet 2x plus petit)
- âœ… Aucun data quality issue
- âœ… IntÃ©gritÃ© rÃ©fÃ©rentielle 100%

## ğŸ“š RÃ©fÃ©rences

- Apache Spark Documentation: https://spark.apache.org/docs/latest/
- PySpark API: https://spark.apache.org/docs/latest/api/python/
- Star Schema: https://en.wikipedia.org/wiki/Star_schema

---

**Rapport gÃ©nÃ©rÃ© le**: DÃ©cembre 8, 2025
**Auteur**: Badr TAJINI
**Institution**: ESIEE Paris
