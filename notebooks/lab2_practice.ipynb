{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1fea1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/09 20:41:17 WARN Utils: Your hostname, Wandaogo, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/12/09 20:41:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/09 20:41:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark 4.0.1 initialized\n",
      "‚úÖ Tous les sch√©mas d√©finis\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from datetime import datetime as _dt\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "# Initialise Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"de1-lab2\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"‚úÖ Spark {spark.version} initialized\")\n",
    "\n",
    "# R√©pertoires\n",
    "base = \"data/\"\n",
    "os.makedirs(base, exist_ok=True)\n",
    "os.makedirs(\"proof\", exist_ok=True)\n",
    "os.makedirs(\"outputs/lab2\", exist_ok=True)\n",
    "\n",
    "# Sch√©mas explicites\n",
    "customers_schema = T.StructType([\n",
    "    T.StructField(\"customer_id\", T.IntegerType(), False),\n",
    "    T.StructField(\"name\", T.StringType(), True),\n",
    "    T.StructField(\"email\", T.StringType(), True),\n",
    "    T.StructField(\"created_at\", T.TimestampType(), True),\n",
    "])\n",
    "\n",
    "brands_schema = T.StructType([\n",
    "    T.StructField(\"brand_id\", T.IntegerType(), False),\n",
    "    T.StructField(\"brand_name\", T.StringType(), True),\n",
    "])\n",
    "\n",
    "categories_schema = T.StructType([\n",
    "    T.StructField(\"category_id\", T.IntegerType(), False),\n",
    "    T.StructField(\"category_name\", T.StringType(), True),\n",
    "])\n",
    "\n",
    "products_schema = T.StructType([\n",
    "    T.StructField(\"product_id\", T.IntegerType(), False),\n",
    "    T.StructField(\"product_name\", T.StringType(), True),\n",
    "    T.StructField(\"brand_id\", T.IntegerType(), True),\n",
    "    T.StructField(\"category_id\", T.IntegerType(), True),\n",
    "    T.StructField(\"price\", T.DoubleType(), True),\n",
    "])\n",
    "\n",
    "orders_schema = T.StructType([\n",
    "    T.StructField(\"order_id\", T.IntegerType(), False),\n",
    "    T.StructField(\"customer_id\", T.IntegerType(), True),\n",
    "    T.StructField(\"order_date\", T.TimestampType(), True),\n",
    "])\n",
    "\n",
    "order_items_schema = T.StructType([\n",
    "    T.StructField(\"order_item_id\", T.IntegerType(), False),\n",
    "    T.StructField(\"order_id\", T.IntegerType(), True),\n",
    "    T.StructField(\"product_id\", T.IntegerType(), True),\n",
    "    T.StructField(\"quantity\", T.IntegerType(), True),\n",
    "    T.StructField(\"unit_price\", T.DoubleType(), True),\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Tous les sch√©mas d√©finis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71791191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä G√©n√©ration des donn√©es de test...\n",
      "\n",
      "‚úÖ lab2_customers.csv: 10 rows\n",
      "‚úÖ lab2_brands.csv: 5 rows\n",
      "‚úÖ lab2_categories.csv: 5 rows\n",
      "‚úÖ lab2_products.csv: 20 rows\n",
      "‚úÖ lab2_orders.csv: 50 rows\n",
      "‚úÖ lab2_order_items.csv: 100 rows\n",
      "\n",
      "============================================================\n",
      "‚úÖ Toutes les donn√©es g√©n√©r√©es avec succ√®s!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "print(\"üìä G√©n√©ration des donn√©es de test...\\n\")\n",
    "\n",
    "# 1. Customers\n",
    "customers_data = {\n",
    "    \"customer_id\": list(range(1, 11)),\n",
    "    \"name\": [\"Alice Martin\", \"Bob Dupont\", \"Caroline Lefevre\", \"David Laurent\", \n",
    "             \"Emma Rousseau\", \"Frank Moreau\", \"Gabrielle Petit\", \"Henry Bernard\",\n",
    "             \"Isabelle Dubois\", \"Jean-Pierre Garnier\"],\n",
    "    \"email\": [f\"customer{i}@email.com\" for i in range(1, 11)],\n",
    "    \"created_at\": [datetime(2024, 1, 1) + timedelta(days=i*10) for i in range(10)]\n",
    "}\n",
    "df_customers = pd.DataFrame(customers_data)\n",
    "df_customers.to_csv(f\"{base}lab2_customers.csv\", index=False)\n",
    "print(f\"‚úÖ lab2_customers.csv: {len(df_customers)} rows\")\n",
    "\n",
    "# 2. Brands\n",
    "brands_data = {\n",
    "    \"brand_id\": [1, 2, 3, 4, 5],\n",
    "    \"brand_name\": [\"TechCorp\", \"ElectroMax\", \"GadgetPlus\", \"ProTech\", \"InnovateLabs\"]\n",
    "}\n",
    "df_brands = pd.DataFrame(brands_data)\n",
    "df_brands.to_csv(f\"{base}lab2_brands.csv\", index=False)\n",
    "print(f\"‚úÖ lab2_brands.csv: {len(df_brands)} rows\")\n",
    "\n",
    "# 3. Categories\n",
    "categories_data = {\n",
    "    \"category_id\": [1, 2, 3, 4, 5],\n",
    "    \"category_name\": [\"Smartphones\", \"Laptops\", \"Tablets\", \"Accessories\", \"Wearables\"]\n",
    "}\n",
    "df_categories = pd.DataFrame(categories_data)\n",
    "df_categories.to_csv(f\"{base}lab2_categories.csv\", index=False)\n",
    "print(f\"‚úÖ lab2_categories.csv: {len(df_categories)} rows\")\n",
    "\n",
    "# 4. Products\n",
    "products_data = {\n",
    "    \"product_id\": list(range(1, 21)),\n",
    "    \"product_name\": [\n",
    "        \"iPhone 15\", \"Samsung Galaxy S24\", \"Google Pixel 8\", \"OnePlus 12\",\n",
    "        \"MacBook Pro\", \"Dell XPS 15\", \"HP Pavilion\", \"Lenovo ThinkPad\",\n",
    "        \"iPad Air\", \"Samsung Tab S9\", \"Apple Watch Ultra\", \"Airpods Pro\",\n",
    "        \"USB-C Cable\", \"Phone Case\", \"Screen Protector\", \"Wireless Charger\",\n",
    "        \"Xiaomi Band 8\", \"Fitbit Charge 6\", \"AirTag\", \"MagSafe Mount\"\n",
    "    ],\n",
    "    \"brand_id\": [1, 2, 1, 3, 1, 2, 2, 4, 1, 2, 1, 1, 5, 5, 5, 5, 3, 4, 1, 5],\n",
    "    \"category_id\": [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 5, 5, 4, 4, 4, 4, 5, 5, 4, 4],\n",
    "    \"price\": [999.99, 899.99, 799.99, 749.99, 1999.99, 1499.99, 699.99, 1299.99,\n",
    "              699.99, 599.99, 799.99, 249.99, 19.99, 14.99, 9.99, 29.99,\n",
    "              79.99, 149.99, 99.99, 39.99]\n",
    "}\n",
    "df_products = pd.DataFrame(products_data)\n",
    "df_products.to_csv(f\"{base}lab2_products.csv\", index=False)\n",
    "print(f\"‚úÖ lab2_products.csv: {len(df_products)} rows\")\n",
    "\n",
    "# 5. Orders\n",
    "orders_data = {\n",
    "    \"order_id\": list(range(1, 51)),\n",
    "    \"customer_id\": [random.randint(1, 10) for _ in range(50)],\n",
    "    \"order_date\": [datetime(2024, 6, 1) + timedelta(days=random.randint(0, 180)) for _ in range(50)]\n",
    "}\n",
    "df_orders = pd.DataFrame(orders_data)\n",
    "df_orders.to_csv(f\"{base}lab2_orders.csv\", index=False)\n",
    "print(f\"‚úÖ lab2_orders.csv: {len(df_orders)} rows\")\n",
    "\n",
    "# 6. Order Items\n",
    "order_items_data = {\n",
    "    \"order_item_id\": list(range(1, 101)),\n",
    "    \"order_id\": [random.choice(df_orders[\"order_id\"]) for _ in range(100)],\n",
    "    \"product_id\": [random.randint(1, 20) for _ in range(100)],\n",
    "    \"quantity\": [random.randint(1, 5) for _ in range(100)],\n",
    "}\n",
    "df_order_items = pd.DataFrame(order_items_data)\n",
    "\n",
    "# Ajoute unit_price depuis products\n",
    "df_order_items = df_order_items.merge(df_products[[\"product_id\", \"price\"]], on=\"product_id\")\n",
    "df_order_items[\"unit_price\"] = df_order_items[\"price\"]\n",
    "df_order_items = df_order_items[[\"order_item_id\", \"order_id\", \"product_id\", \"quantity\", \"unit_price\"]]\n",
    "df_order_items.to_csv(f\"{base}lab2_order_items.csv\", index=False)\n",
    "print(f\"‚úÖ lab2_order_items.csv: {len(df_order_items)} rows\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Toutes les donn√©es g√©n√©r√©es avec succ√®s!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed91425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üì• √âTAPE 1: INGESTION DES DONN√âES\n",
      "============================================================\n",
      "\n",
      "üìä Comptages des tables op√©rationnelles:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customers      :   10 lignes\n",
      "   brands         :    5 lignes\n",
      "   categories     :    5 lignes\n",
      "   products       :   20 lignes\n",
      "   orders         :   50 lignes\n",
      "   order_items    :  100 lignes\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìà Profils des donn√©es:\n",
      "\n",
      "customers:\n",
      "+-----------+----------------+-------------------+-------------------+\n",
      "|customer_id|            name|              email|         created_at|\n",
      "+-----------+----------------+-------------------+-------------------+\n",
      "|          1|    Alice Martin|customer1@email.com|2024-01-01 00:00:00|\n",
      "|          2|      Bob Dupont|customer2@email.com|2024-01-11 00:00:00|\n",
      "|          3|Caroline Lefevre|customer3@email.com|2024-01-21 00:00:00|\n",
      "+-----------+----------------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "orders:\n",
      "+--------+-----------+-------------------+\n",
      "|order_id|customer_id|         order_date|\n",
      "+--------+-----------+-------------------+\n",
      "|       1|          6|2024-10-01 00:00:00|\n",
      "|       2|          9|2024-09-05 00:00:00|\n",
      "|       3|          1|2024-06-23 00:00:00|\n",
      "+--------+-----------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "order_items:\n",
      "+-------------+--------+----------+--------+----------+\n",
      "|order_item_id|order_id|product_id|quantity|unit_price|\n",
      "+-------------+--------+----------+--------+----------+\n",
      "|            1|      49|         6|       4|   1499.99|\n",
      "|            2|      17|         2|       2|    899.99|\n",
      "|            3|      26|        18|       4|    149.99|\n",
      "+-------------+--------+----------+--------+----------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì• √âTAPE 1: INGESTION DES DONN√âES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Charge tous les CSV avec les sch√©mas\n",
    "customers = spark.read \\\n",
    "    .schema(customers_schema) \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .csv(f\"{base}lab2_customers.csv\")\n",
    "\n",
    "brands = spark.read \\\n",
    "    .schema(brands_schema) \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .csv(f\"{base}lab2_brands.csv\")\n",
    "\n",
    "categories = spark.read \\\n",
    "    .schema(categories_schema) \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .csv(f\"{base}lab2_categories.csv\")\n",
    "\n",
    "products = spark.read \\\n",
    "    .schema(products_schema) \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .csv(f\"{base}lab2_products.csv\")\n",
    "\n",
    "orders = spark.read \\\n",
    "    .schema(orders_schema) \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .csv(f\"{base}lab2_orders.csv\")\n",
    "\n",
    "order_items = spark.read \\\n",
    "    .schema(order_items_schema) \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .csv(f\"{base}lab2_order_items.csv\")\n",
    "\n",
    "# Affiche les comptages\n",
    "print(\"\\nüìä Comptages des tables op√©rationnelles:\\n\")\n",
    "for name, df in [(\"customers\", customers), (\"brands\", brands), (\"categories\", categories),\n",
    "                  (\"products\", products), (\"orders\", orders), (\"order_items\", order_items)]:\n",
    "    count = df.count()\n",
    "    print(f\"   {name:15s}: {count:4d} lignes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Profil des donn√©es\n",
    "print(\"\\nüìà Profils des donn√©es:\\n\")\n",
    "print(\"customers:\")\n",
    "customers.show(3)\n",
    "print(\"\\norders:\")\n",
    "orders.show(3)\n",
    "print(\"\\norder_items:\")\n",
    "order_items.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f595cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîç PLAN D'EX√âCUTION - INGESTION\n",
      "============================================================\n",
      "\n",
      "üìã Plan Spark (format√©):\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (11)\n",
      "+- HashAggregate (10)\n",
      "   +- Exchange (9)\n",
      "      +- HashAggregate (8)\n",
      "         +- Project (7)\n",
      "            +- BroadcastHashJoin Inner BuildLeft (6)\n",
      "               :- BroadcastExchange (3)\n",
      "               :  +- Filter (2)\n",
      "               :     +- Scan csv  (1)\n",
      "               +- Filter (5)\n",
      "                  +- Scan csv  (4)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [1]: [order_id#13]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_orders.csv]\n",
      "PushedFilters: [IsNotNull(order_id)]\n",
      "ReadSchema: struct<order_id:int>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [order_id#13]\n",
      "Condition : isnotnull(order_id#13)\n",
      "\n",
      "(3) BroadcastExchange\n",
      "Input [1]: [order_id#13]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=257]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [1]: [order_id#17]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_order_items.csv]\n",
      "PushedFilters: [IsNotNull(order_id)]\n",
      "ReadSchema: struct<order_id:int>\n",
      "\n",
      "(5) Filter\n",
      "Input [1]: [order_id#17]\n",
      "Condition : isnotnull(order_id#17)\n",
      "\n",
      "(6) BroadcastHashJoin\n",
      "Left keys [1]: [order_id#13]\n",
      "Right keys [1]: [order_id#17]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(7) Project\n",
      "Output [1]: [order_id#13]\n",
      "Input [2]: [order_id#13, order_id#17]\n",
      "\n",
      "(8) HashAggregate\n",
      "Input [1]: [order_id#13]\n",
      "Keys [1]: [order_id#13]\n",
      "Functions: []\n",
      "Aggregate Attributes: []\n",
      "Results [1]: [order_id#13]\n",
      "\n",
      "(9) Exchange\n",
      "Input [1]: [order_id#13]\n",
      "Arguments: hashpartitioning(order_id#13, 200), ENSURE_REQUIREMENTS, [plan_id=262]\n",
      "\n",
      "(10) HashAggregate\n",
      "Input [1]: [order_id#13]\n",
      "Keys [1]: [order_id#13]\n",
      "Functions: []\n",
      "Aggregate Attributes: []\n",
      "Results [1]: [order_id#13]\n",
      "\n",
      "(11) AdaptiveSparkPlan\n",
      "Output [1]: [order_id#13]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "‚úÖ Plan sauvegard√© dans proof/plan_ingest.txt\n",
      "‚úÖ R√©sum√© sauvegard√© dans proof/ingestion_summary.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç PLAN D'EX√âCUTION - INGESTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plan d'ingestion simple\n",
    "ingest = orders.join(order_items, \"order_id\").select(\"order_id\").distinct()\n",
    "\n",
    "print(\"\\nüìã Plan Spark (format√©):\\n\")\n",
    "ingest.explain(\"formatted\")\n",
    "\n",
    "# Sauvegarde la preuve\n",
    "with open(\"proof/plan_ingest.txt\", \"w\") as f:\n",
    "    f.write(f\"=== PLAN INGESTION ===\\n\")\n",
    "    f.write(f\"Timestamp: {_dt.now()}\\n\\n\")\n",
    "    f.write(ingest._jdf.queryExecution().executedPlan().toString())\n",
    "\n",
    "print(\"‚úÖ Plan sauvegard√© dans proof/plan_ingest.txt\")\n",
    "\n",
    "# Sauvegarde aussi un CSV avec le plan\n",
    "with open(\"proof/ingestion_summary.csv\", \"w\") as f:\n",
    "    f.write(\"Op√©ration,Lignes,D√©tails\\n\")\n",
    "    f.write(f\"Orders,{orders.count()},Toutes les commandes\\n\")\n",
    "    f.write(f\"OrderItems,{order_items.count()},Tous les articles\\n\")\n",
    "    f.write(f\"Join Result,{ingest.count()},Commandes avec articles\\n\")\n",
    "\n",
    "print(\"‚úÖ R√©sum√© sauvegard√© dans proof/ingestion_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7ced03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîë √âTAPE 2: FONCTION CL√â DE SUBSTITUTION\n",
      "============================================================\n",
      "\n",
      "‚úÖ Fonction sk() d√©finie:\n",
      "   - Utilise xxhash64 pour hash stable\n",
      "   - Retourne valeur positive avec abs()\n",
      "   - D√©terministe (m√™me cl√© naturelle = m√™me SK)\n",
      "   \n",
      "Exemple:\n",
      "  sk([\"customer_id\"]) ‚Üí hash stable du customer_id\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîë √âTAPE 2: FONCTION CL√â DE SUBSTITUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def sk(cols):\n",
    "    \"\"\"\n",
    "    G√©n√®re une cl√© de substitution stable 64-bit positive\n",
    "    √† partir de cl√©s naturelles en utilisant xxhash64\n",
    "    \"\"\"\n",
    "    return F.abs(F.xxhash64(*[F.col(c) for c in cols]))\n",
    "\n",
    "print(\"\"\"\n",
    "‚úÖ Fonction sk() d√©finie:\n",
    "   - Utilise xxhash64 pour hash stable\n",
    "   - Retourne valeur positive avec abs()\n",
    "   - D√©terministe (m√™me cl√© naturelle = m√™me SK)\n",
    "   \n",
    "Exemple:\n",
    "  sk([\"customer_id\"]) ‚Üí hash stable du customer_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdee49ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìê √âTAPE 3: CONSTRUCTION DES DIMENSIONS\n",
      "============================================================\n",
      "\n",
      "üìä Dimensions cr√©√©es:\n",
      "\n",
      "dim_customer:  10 rows\n",
      "+-------------------+-----------+----------------+-------------------+-------------------+\n",
      "|        customer_sk|customer_id|            name|              email|         created_at|\n",
      "+-------------------+-----------+----------------+-------------------+-------------------+\n",
      "|6698625589789238999|          1|    Alice Martin|customer1@email.com|2024-01-01 00:00:00|\n",
      "|8420071140774656230|          2|      Bob Dupont|customer2@email.com|2024-01-11 00:00:00|\n",
      "|6258084186791473711|          3|Caroline Lefevre|customer3@email.com|2024-01-21 00:00:00|\n",
      "+-------------------+-----------+----------------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "dim_brand:     5 rows\n",
      "+-------------------+--------+----------+\n",
      "|           brand_sk|brand_id|brand_name|\n",
      "+-------------------+--------+----------+\n",
      "|6698625589789238999|       1|  TechCorp|\n",
      "|8420071140774656230|       2|ElectroMax|\n",
      "|6258084186791473711|       3|GadgetPlus|\n",
      "+-------------------+--------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "dim_category:  5 rows\n",
      "+-------------------+-----------+-------------+\n",
      "|        category_sk|category_id|category_name|\n",
      "+-------------------+-----------+-------------+\n",
      "|6698625589789238999|          1|  Smartphones|\n",
      "|8420071140774656230|          2|      Laptops|\n",
      "|6258084186791473711|          3|      Tablets|\n",
      "+-------------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "dim_product:   20 rows\n",
      "+-------------------+----------+------------------+-------------------+-------------------+------+\n",
      "|         product_sk|product_id|      product_name|           brand_sk|        category_sk| price|\n",
      "+-------------------+----------+------------------+-------------------+-------------------+------+\n",
      "|6698625589789238999|         1|         iPhone 15|6698625589789238999|6698625589789238999|999.99|\n",
      "|8420071140774656230|         2|Samsung Galaxy S24|8420071140774656230|6698625589789238999|899.99|\n",
      "|6258084186791473711|         3|    Google Pixel 8|6698625589789238999|6698625589789238999|799.99|\n",
      "+-------------------+----------+------------------+-------------------+-------------------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "‚úÖ Dimensions sauvegard√©es dans proof/dimensions_summary.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìê √âTAPE 3: CONSTRUCTION DES DIMENSIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# dim_customer\n",
    "dim_customer = customers.select(\n",
    "    sk([\"customer_id\"]).alias(\"customer_sk\"),\n",
    "    \"customer_id\",\n",
    "    \"name\",\n",
    "    \"email\",\n",
    "    \"created_at\"\n",
    ")\n",
    "\n",
    "# dim_brand\n",
    "dim_brand = brands.select(\n",
    "    sk([\"brand_id\"]).alias(\"brand_sk\"),\n",
    "    \"brand_id\",\n",
    "    \"brand_name\"\n",
    ")\n",
    "\n",
    "# dim_category\n",
    "dim_category = categories.select(\n",
    "    sk([\"category_id\"]).alias(\"category_sk\"),\n",
    "    \"category_id\",\n",
    "    \"category_name\"\n",
    ")\n",
    "\n",
    "# dim_product\n",
    "dim_product = products.select(\n",
    "    sk([\"product_id\"]).alias(\"product_sk\"),\n",
    "    \"product_id\",\n",
    "    \"product_name\",\n",
    "    sk([\"brand_id\"]).alias(\"brand_sk\"),\n",
    "    sk([\"category_id\"]).alias(\"category_sk\"),\n",
    "    \"price\"\n",
    ")\n",
    "\n",
    "# Affiche les r√©sultats\n",
    "print(\"\\nüìä Dimensions cr√©√©es:\\n\")\n",
    "print(f\"dim_customer:  {dim_customer.count()} rows\")\n",
    "dim_customer.show(3)\n",
    "\n",
    "print(f\"\\ndim_brand:     {dim_brand.count()} rows\")\n",
    "dim_brand.show(3)\n",
    "\n",
    "print(f\"\\ndim_category:  {dim_category.count()} rows\")\n",
    "dim_category.show(3)\n",
    "\n",
    "print(f\"\\ndim_product:   {dim_product.count()} rows\")\n",
    "dim_product.show(3)\n",
    "\n",
    "# Sauvegarde les statistiques\n",
    "with open(\"proof/dimensions_summary.csv\", \"w\") as f:\n",
    "    f.write(\"Dimension,Lignes,Colonnes\\n\")\n",
    "    f.write(f\"dim_customer,{dim_customer.count()},5\\n\")\n",
    "    f.write(f\"dim_brand,{dim_brand.count()},3\\n\")\n",
    "    f.write(f\"dim_category,{dim_category.count()},3\\n\")\n",
    "    f.write(f\"dim_product,{dim_product.count()},6\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ Dimensions sauvegard√©es dans proof/dimensions_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d0bb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìÖ √âTAPE 4: DIMENSION DATE\n",
      "============================================================\n",
      "\n",
      "üìä dim_date: 45 jours uniques\n",
      "\n",
      "+-------------------+----------+----+-----+---+---+-------+------------+\n",
      "|date_sk            |date      |year|month|day|dow|quarter|week_of_year|\n",
      "+-------------------+----------+----+-----+---+---+-------+------------+\n",
      "|1307272247578339239|2024-08-27|2024|8    |27 |Tue|3      |35          |\n",
      "|4822692307583801426|2024-11-02|2024|11   |2  |Sat|4      |44          |\n",
      "|8872159615915572291|2024-10-24|2024|10   |24 |Thu|4      |43          |\n",
      "|7593407256401673777|2024-09-10|2024|9    |10 |Tue|3      |37          |\n",
      "|3799421252167961828|2024-08-05|2024|8    |5  |Mon|3      |32          |\n",
      "|2795412895394378798|2024-10-25|2024|10   |25 |Fri|4      |43          |\n",
      "|2857658719716137024|2024-07-18|2024|7    |18 |Thu|3      |29          |\n",
      "|5690026203634146595|2024-08-29|2024|8    |29 |Thu|3      |35          |\n",
      "|4425985170592395865|2024-08-07|2024|8    |7  |Wed|3      |32          |\n",
      "|2425830812311755070|2024-07-17|2024|7    |17 |Wed|3      |29          |\n",
      "+-------------------+----------+----+-----+---+---+-------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "üìà Plage temporelle:\n",
      "   Min date: 2024-06-14 00:00:00\n",
      "   Max date: 2024-11-22 00:00:00\n",
      "\n",
      "‚úÖ Dimension date sauvegard√©e\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÖ √âTAPE 4: DIMENSION DATE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from pyspark.sql import Window as W\n",
    "\n",
    "# Extrait les dates uniques\n",
    "dates = orders.select(F.to_date(\"order_date\").alias(\"date\")).distinct()\n",
    "\n",
    "# Construit dim_date\n",
    "dim_date = dates.select(\n",
    "    sk([\"date\"]).alias(\"date_sk\"),\n",
    "    F.col(\"date\"),\n",
    "    F.year(\"date\").alias(\"year\"),\n",
    "    F.month(\"date\").alias(\"month\"),\n",
    "    F.dayofmonth(\"date\").alias(\"day\"),\n",
    "    F.date_format(\"date\", \"E\").alias(\"dow\"),  # Day of week\n",
    "    F.quarter(\"date\").alias(\"quarter\"),\n",
    "    F.weekofyear(\"date\").alias(\"week_of_year\")\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä dim_date: {dim_date.count()} jours uniques\\n\")\n",
    "dim_date.show(10, truncate=False)\n",
    "\n",
    "# Statistiques temporelles\n",
    "min_date = orders.agg(F.min(\"order_date\")).collect()[0][0]\n",
    "max_date = orders.agg(F.max(\"order_date\")).collect()[0][0]\n",
    "\n",
    "print(f\"\\nüìà Plage temporelle:\")\n",
    "print(f\"   Min date: {min_date}\")\n",
    "print(f\"   Max date: {max_date}\")\n",
    "\n",
    "# Sauvegarde\n",
    "with open(\"proof/date_dimension_summary.csv\", \"w\") as f:\n",
    "    f.write(\"M√©trique,Valeur\\n\")\n",
    "    f.write(f\"Jours uniques,{dim_date.count()}\\n\")\n",
    "    f.write(f\"Date min,{min_date}\\n\")\n",
    "    f.write(f\"Date max,{max_date}\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ Dimension date sauvegard√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192c16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plus propre: join puis projection imm√©diate\n",
    "df_fact = (oi\n",
    "    .join(p, F.col(\"oi.product_id\") == F.col(\"p.product_id\"), \"inner\")\n",
    "    .join(o, F.col(\"oi.order_id\") == F.col(\"o.order_id\"), \"inner\")\n",
    "    .join(c, F.col(\"o.customer_id\") == F.col(\"c.customer_id\"), \"inner\")\n",
    ")\n",
    "\n",
    "# Projet imm√©diatement pour √©viter les ambigu√Øt√©s\n",
    "df_fact = df_fact.select(\n",
    "    F.col(\"oi.order_id\").alias(\"order_id\"),\n",
    "    F.col(\"oi.product_id\").alias(\"product_id\"),\n",
    "    F.col(\"oi.quantity\").alias(\"quantity\"),\n",
    "    F.col(\"oi.unit_price\").alias(\"unit_price\"),\n",
    "    F.col(\"o.customer_id\").alias(\"customer_id\"),\n",
    "    F.col(\"o.order_date\").alias(\"order_date\"),\n",
    "    F.col(\"p.price\").alias(\"product_price\")\n",
    ")\n",
    "\n",
    "# Maintenant plus d'ambigu√Øt√©!\n",
    "df_fact = (df_fact\n",
    "    .withColumn(\"date\", F.to_date(\"order_date\"))\n",
    "    .withColumn(\"date_sk\", sk([\"date\"]))\n",
    "    .withColumn(\"customer_sk\", sk([\"customer_id\"]))\n",
    "    .withColumn(\"product_sk\", sk([\"product_id\"]))\n",
    "    .withColumn(\"subtotal\", F.col(\"quantity\") * F.col(\"unit_price\"))\n",
    "    .withColumn(\"year\", F.year(\"date\"))\n",
    "    .withColumn(\"month\", F.month(\"date\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543a6baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä √âTAPE 5: CONSTRUCTION DE LA TABLE DE FAITS (PROPRE)\n",
      "============================================================\n",
      "\n",
      "üîó Sequence de joins:\n",
      "   order_items (oi)\n",
      "   ‚Üí JOIN products (p)\n",
      "   ‚Üí JOIN orders (o)\n",
      "   ‚Üí JOIN customers (c)\n",
      "\n",
      "‚úÖ fact_sales construite avec succ√®s: 100 lignes\n",
      "\n",
      "+--------+-------------------+-------------------+-------------------+--------+----------+------------------+----+-----+\n",
      "|order_id|            date_sk|        customer_sk|         product_sk|quantity|unit_price|          subtotal|year|month|\n",
      "+--------+-------------------+-------------------+-------------------+--------+----------+------------------+----+-----+\n",
      "|      49|5690026203634146595|8420071140774656230| 233500712460350175|       4|   1499.99|           5999.96|2024|    8|\n",
      "|      17|3271524206859782347|8420071140774656230|8420071140774656230|       2|    899.99|           1799.98|2024|   10|\n",
      "|      26|6437972260669345058| 504019808641096632|5346497071442387076|       4|    149.99|            599.96|2024|   11|\n",
      "|       2|8799929592043627498|2852032610340310743|6698625589789238999|       2|    999.99|           1999.98|2024|    9|\n",
      "|      50|4575922205773423797|2786828215451145335|8285521376477742517|       3|   1299.99|3899.9700000000003|2024|   11|\n",
      "+--------+-------------------+-------------------+-------------------+--------+----------+------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "üìà Statistiques fact_sales:\n",
      "   Nombre de commandes: 100\n",
      "   Quantit√© totale: 295\n",
      "   GMV total: $196872.05\n",
      "   AOV moyen: $1968.72\n",
      "   Min commande: $9.99\n",
      "   Max commande: $9999.95\n",
      "\n",
      "‚úÖ fact_sales sauvegard√©e dans proof/fact_sales_summary.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä √âTAPE 5: CONSTRUCTION DE LA TABLE DE FAITS (PROPRE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Aliases\n",
    "oi = order_items.alias(\"oi\")\n",
    "p = products.alias(\"p\")\n",
    "o = orders.alias(\"o\")\n",
    "c = customers.alias(\"c\")\n",
    "\n",
    "print(\"\\nüîó Sequence de joins:\")\n",
    "print(\"   order_items (oi)\")\n",
    "print(\"   ‚Üí JOIN products (p)\")\n",
    "print(\"   ‚Üí JOIN orders (o)\")\n",
    "print(\"   ‚Üí JOIN customers (c)\")\n",
    "\n",
    "# √âTAPE 1: Joins\n",
    "df_joined = (oi\n",
    "    .join(p, F.col(\"oi.product_id\") == F.col(\"p.product_id\"), \"inner\")\n",
    "    .join(o, F.col(\"oi.order_id\") == F.col(\"o.order_id\"), \"inner\")\n",
    "    .join(c, F.col(\"o.customer_id\") == F.col(\"c.customer_id\"), \"inner\")\n",
    ")\n",
    "\n",
    "# √âTAPE 2: Projection imm√©diate pour √©liminer l'ambigu√Øt√©\n",
    "df_joined = df_joined.select(\n",
    "    F.col(\"oi.order_id\").alias(\"order_id\"),\n",
    "    F.col(\"oi.product_id\").alias(\"product_id\"),\n",
    "    F.col(\"oi.quantity\").alias(\"quantity\"),\n",
    "    F.col(\"oi.unit_price\").alias(\"unit_price\"),\n",
    "    F.col(\"o.customer_id\").alias(\"customer_id\"),\n",
    "    F.col(\"o.order_date\").alias(\"order_date\"),\n",
    "    F.col(\"p.price\").alias(\"product_price\")\n",
    ")\n",
    "\n",
    "# √âTAPE 3: Transformations\n",
    "df_fact = (df_joined\n",
    "    .withColumn(\"date\", F.to_date(\"order_date\"))\n",
    "    .withColumn(\"date_sk\", sk([\"date\"]))\n",
    "    .withColumn(\"customer_sk\", sk([\"customer_id\"]))\n",
    "    .withColumn(\"product_sk\", sk([\"product_id\"]))\n",
    "    .withColumn(\"quantity\", F.col(\"quantity\").cast(\"int\"))\n",
    "    .withColumn(\"unit_price\", F.col(\"unit_price\").cast(\"double\"))\n",
    "    .withColumn(\"subtotal\", F.col(\"quantity\") * F.col(\"unit_price\"))\n",
    "    .withColumn(\"year\", F.year(\"date\"))\n",
    "    .withColumn(\"month\", F.month(\"date\"))\n",
    "    .select(\n",
    "        \"order_id\",\n",
    "        \"date_sk\",\n",
    "        \"customer_sk\",\n",
    "        \"product_sk\",\n",
    "        \"quantity\",\n",
    "        \"unit_price\",\n",
    "        \"subtotal\",\n",
    "        \"year\",\n",
    "        \"month\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ fact_sales construite avec succ√®s: {df_fact.count()} lignes\\n\")\n",
    "df_fact.show(5)\n",
    "\n",
    "# Statistiques\n",
    "print(f\"\\nüìà Statistiques fact_sales:\")\n",
    "fact_stats = df_fact.agg(\n",
    "    F.count(\"order_id\").alias(\"nombre_orders\"),\n",
    "    F.sum(\"quantity\").alias(\"total_quantity\"),\n",
    "    F.sum(\"subtotal\").alias(\"total_gmv\"),\n",
    "    F.avg(\"subtotal\").alias(\"avg_order_value\"),\n",
    "    F.min(\"subtotal\").alias(\"min_order\"),\n",
    "    F.max(\"subtotal\").alias(\"max_order\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"   Nombre de commandes: {int(fact_stats['nombre_orders'])}\")\n",
    "print(f\"   Quantit√© totale: {int(fact_stats['total_quantity'])}\")\n",
    "print(f\"   GMV total: ${fact_stats['total_gmv']:.2f}\")\n",
    "print(f\"   AOV moyen: ${fact_stats['avg_order_value']:.2f}\")\n",
    "print(f\"   Min commande: ${fact_stats['min_order']:.2f}\")\n",
    "print(f\"   Max commande: ${fact_stats['max_order']:.2f}\")\n",
    "\n",
    "# Sauvegarde les stats\n",
    "with open(\"proof/fact_sales_summary.csv\", \"w\") as f:\n",
    "    f.write(\"M√©trique,Valeur\\n\")\n",
    "    f.write(f\"Nombre de commandes,{int(fact_stats['nombre_orders'])}\\n\")\n",
    "    f.write(f\"Quantit√© totale,{int(fact_stats['total_quantity'])}\\n\")\n",
    "    f.write(f\"GMV total,${fact_stats['total_gmv']:.2f}\\n\")\n",
    "    f.write(f\"AOV moyen,${fact_stats['avg_order_value']:.2f}\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ fact_sales sauvegard√©e dans proof/fact_sales_summary.csv\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9258883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîç PLAN D'EX√âCUTION - FACT_SALES\n",
      "============================================================\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (19)\n",
      "+- Project (18)\n",
      "   +- Project (17)\n",
      "      +- BroadcastHashJoin Inner BuildRight (16)\n",
      "         :- Project (12)\n",
      "         :  +- BroadcastHashJoin Inner BuildRight (11)\n",
      "         :     :- Project (7)\n",
      "         :     :  +- BroadcastHashJoin Inner BuildRight (6)\n",
      "         :     :     :- Filter (2)\n",
      "         :     :     :  +- Scan csv  (1)\n",
      "         :     :     +- BroadcastExchange (5)\n",
      "         :     :        +- Filter (4)\n",
      "         :     :           +- Scan csv  (3)\n",
      "         :     +- BroadcastExchange (10)\n",
      "         :        +- Filter (9)\n",
      "         :           +- Scan csv  (8)\n",
      "         +- BroadcastExchange (15)\n",
      "            +- Filter (14)\n",
      "               +- Scan csv  (13)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [4]: [order_id#17, product_id#18, quantity#19, unit_price#20]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_order_items.csv]\n",
      "PushedFilters: [IsNotNull(product_id), IsNotNull(order_id)]\n",
      "ReadSchema: struct<order_id:int,product_id:int,quantity:int,unit_price:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [4]: [order_id#17, product_id#18, quantity#19, unit_price#20]\n",
      "Condition : (isnotnull(product_id#18) AND isnotnull(order_id#17))\n",
      "\n",
      "(3) Scan csv \n",
      "Output [1]: [product_id#8]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_products.csv]\n",
      "PushedFilters: [IsNotNull(product_id)]\n",
      "ReadSchema: struct<product_id:int>\n",
      "\n",
      "(4) Filter\n",
      "Input [1]: [product_id#8]\n",
      "Condition : isnotnull(product_id#8)\n",
      "\n",
      "(5) BroadcastExchange\n",
      "Input [1]: [product_id#8]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2150]\n",
      "\n",
      "(6) BroadcastHashJoin\n",
      "Left keys [1]: [product_id#18]\n",
      "Right keys [1]: [product_id#8]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(7) Project\n",
      "Output [4]: [order_id#17, product_id#18, quantity#19, unit_price#20]\n",
      "Input [5]: [order_id#17, product_id#18, quantity#19, unit_price#20, product_id#8]\n",
      "\n",
      "(8) Scan csv \n",
      "Output [3]: [order_id#13, customer_id#14, order_date#15]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_orders.csv]\n",
      "PushedFilters: [IsNotNull(order_id), IsNotNull(customer_id)]\n",
      "ReadSchema: struct<order_id:int,customer_id:int,order_date:timestamp>\n",
      "\n",
      "(9) Filter\n",
      "Input [3]: [order_id#13, customer_id#14, order_date#15]\n",
      "Condition : (isnotnull(order_id#13) AND isnotnull(customer_id#14))\n",
      "\n",
      "(10) BroadcastExchange\n",
      "Input [3]: [order_id#13, customer_id#14, order_date#15]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2154]\n",
      "\n",
      "(11) BroadcastHashJoin\n",
      "Left keys [1]: [order_id#17]\n",
      "Right keys [1]: [order_id#13]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(12) Project\n",
      "Output [6]: [order_id#17, product_id#18, quantity#19, unit_price#20, customer_id#14, order_date#15]\n",
      "Input [7]: [order_id#17, product_id#18, quantity#19, unit_price#20, order_id#13, customer_id#14, order_date#15]\n",
      "\n",
      "(13) Scan csv \n",
      "Output [1]: [customer_id#0]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_customers.csv]\n",
      "PushedFilters: [IsNotNull(customer_id)]\n",
      "ReadSchema: struct<customer_id:int>\n",
      "\n",
      "(14) Filter\n",
      "Input [1]: [customer_id#0]\n",
      "Condition : isnotnull(customer_id#0)\n",
      "\n",
      "(15) BroadcastExchange\n",
      "Input [1]: [customer_id#0]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2158]\n",
      "\n",
      "(16) BroadcastHashJoin\n",
      "Left keys [1]: [customer_id#14]\n",
      "Right keys [1]: [customer_id#0]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(17) Project\n",
      "Output [6]: [order_id#17, product_id#18, quantity#19, unit_price#20, customer_id#14, cast(order_date#15 as date) AS date#392]\n",
      "Input [7]: [order_id#17, product_id#18, quantity#19, unit_price#20, customer_id#14, order_date#15, customer_id#0]\n",
      "\n",
      "(18) Project\n",
      "Output [9]: [order_id#17, abs(xxhash64(date#392, 42)) AS date_sk#393L, abs(xxhash64(customer_id#14, 42)) AS customer_sk#394L, abs(xxhash64(product_id#18, 42)) AS product_sk#395L, quantity#19, unit_price#20, (cast(quantity#19 as double) * unit_price#20) AS subtotal#398, year(date#392) AS year#399, month(date#392) AS month#400]\n",
      "Input [6]: [order_id#17, product_id#18, quantity#19, unit_price#20, customer_id#14, date#392]\n",
      "\n",
      "(19) AdaptiveSparkPlan\n",
      "Output [9]: [order_id#17, date_sk#393L, customer_sk#394L, product_sk#395L, quantity#19, unit_price#20, subtotal#398, year#399, month#400]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "\n",
      "‚úÖ Plan sauvegard√© dans proof/plan_fact_join.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç PLAN D'EX√âCUTION - FACT_SALES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "df_fact.explain(\"formatted\")\n",
    "\n",
    "# Sauvegarde le plan\n",
    "with open(\"proof/plan_fact_join.txt\", \"w\") as f:\n",
    "    f.write(f\"=== PLAN FACT_SALES ===\\n\")\n",
    "    f.write(f\"Timestamp: {_dt.now()}\\n\\n\")\n",
    "    f.write(df_fact._jdf.queryExecution().executedPlan().toString())\n",
    "\n",
    "print(\"\\n‚úÖ Plan sauvegard√© dans proof/plan_fact_join.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62956f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üíæ √âTAPE 6: √âCRITURE DES SORTIES PARQUET\n",
      "============================================================\n",
      "\n",
      "üìù √âcriture des dimensions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ dim_customer ‚Üí outputs/lab2/dim_customer\n",
      "   ‚úÖ dim_brand ‚Üí outputs/lab2/dim_brand\n",
      "   ‚úÖ dim_category ‚Üí outputs/lab2/dim_category\n",
      "   ‚úÖ dim_product ‚Üí outputs/lab2/dim_product\n",
      "   ‚úÖ dim_date ‚Üí outputs/lab2/dim_date\n",
      "\n",
      "üìù √âcriture de la table de faits (partitionn√©e par year/month)...\n",
      "   ‚úÖ fact_sales ‚Üí outputs/lab2/fact_sales\n",
      "\n",
      "============================================================\n",
      "‚úÖ Toutes les sorties Parquet √©crites avec succ√®s!\n",
      "============================================================\n",
      "\n",
      "üìÇ Structure des sorties:\n",
      "outputs/lab2:\n",
      "total 24K\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 dim_brand\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 dim_category\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 dim_customer\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 dim_date\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 dim_product\n",
      "drwxr-xr-x 3 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 fact_sales\n",
      "\n",
      "outputs/lab2/dim_brand:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo    0 Dec  9 20:49 _SUCCESS\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 1.2K Dec  9 20:49 part-00000-fc4094ef-c911-499c-988e-18aeb0944a64-c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/dim_category:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo    0 Dec  9 20:49 _SUCCESS\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 1.2K Dec  9 20:49 part-00000-1402ab54-95f4-4aec-9019-d4e590fa5d12-c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/dim_customer:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo    0 Dec  9 20:49 _SUCCESS\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 2.0K Dec  9 20:49 part-00000-79204bd6-e80c-4244-8b9e-8bdcef05a561-c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/dim_date:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo    0 Dec  9 20:49 _SUCCESS\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 3.3K Dec  9 20:49 part-00000-e31640ee-0680-4931-b223-66cf148aa595-c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/dim_product:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo    0 Dec  9 20:49 _SUCCESS\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 2.7K Dec  9 20:49 part-00000-d65d61a9-9702-4815-8bdd-4fad64667a61-c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/fact_sales:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo    0 Dec  9 20:49 _SUCCESS\n",
      "drwxr-xr-x 8 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 year=2024\n",
      "\n",
      "outputs/lab2/fact_sales/year=2024:\n",
      "total 24K\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 month=10\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 month=11\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 month=6\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 month=7\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 month=8\n",
      "drwxr-xr-x 2 bibawandaogo bibawandaogo 4.0K Dec  9 20:49 month=9\n",
      "\n",
      "outputs/lab2/fact_sales/year=2024/month=10:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 2.8K Dec  9 20:49 part-00000-6f995a37-e29f-4269-a02d-43c701036080.c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/fact_sales/year=2024/month=11:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 2.9K Dec  9 20:49 part-00000-6f995a37-e29f-4269-a02d-43c701036080.c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/fact_sales/year=2024/month=6:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 2.6K Dec  9 20:49 part-00000-6f995a37-e29f-4269-a02d-43c701036080.c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/fact_sales/year=2024/month=7:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 2.6K Dec  9 20:49 part-00000-6f995a37-e29f-4269-a02d-43c701036080.c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/fact_sales/year=2024/month=8:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 2.8K Dec  9 20:49 part-00000-6f995a37-e29f-4269-a02d-43c701036080.c000.snappy.parquet\n",
      "\n",
      "outputs/lab2/fact_sales/year=2024/month=9:\n",
      "total 4.0K\n",
      "-rw-r--r-- 1 bibawandaogo bibawandaogo 2.8K Dec  9 20:49 part-00000-6f995a37-e29f-4269-a02d-43c701036080.c000.snappy.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ √âTAPE 6: √âCRITURE DES SORTIES PARQUET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "base_out = \"outputs/lab2\"\n",
    "\n",
    "# Cr√©e le r√©pertoire\n",
    "os.makedirs(base_out, exist_ok=True)\n",
    "\n",
    "# √âcrit les dimensions\n",
    "print(\"\\nüìù √âcriture des dimensions...\")\n",
    "\n",
    "(dim_customer.write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(f\"{base_out}/dim_customer\"))\n",
    "print(f\"   ‚úÖ dim_customer ‚Üí {base_out}/dim_customer\")\n",
    "\n",
    "(dim_brand.write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(f\"{base_out}/dim_brand\"))\n",
    "print(f\"   ‚úÖ dim_brand ‚Üí {base_out}/dim_brand\")\n",
    "\n",
    "(dim_category.write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(f\"{base_out}/dim_category\"))\n",
    "print(f\"   ‚úÖ dim_category ‚Üí {base_out}/dim_category\")\n",
    "\n",
    "(dim_product.write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(f\"{base_out}/dim_product\"))\n",
    "print(f\"   ‚úÖ dim_product ‚Üí {base_out}/dim_product\")\n",
    "\n",
    "(dim_date.write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(f\"{base_out}/dim_date\"))\n",
    "print(f\"   ‚úÖ dim_date ‚Üí {base_out}/dim_date\")\n",
    "\n",
    "# √âcrit la table de faits (partitionn√©e par year, month)\n",
    "print(\"\\nüìù √âcriture de la table de faits (partitionn√©e par year/month)...\")\n",
    "(df_fact.write\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"year\", \"month\")\n",
    "    .parquet(f\"{base_out}/fact_sales\"))\n",
    "print(f\"   ‚úÖ fact_sales ‚Üí {base_out}/fact_sales\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Toutes les sorties Parquet √©crites avec succ√®s!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# V√©rifie les fichiers\n",
    "import subprocess\n",
    "result = subprocess.run(f\"ls -lhR {base_out}\", shell=True, capture_output=True, text=True)\n",
    "print(\"\\nüìÇ Structure des sorties:\")\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d022e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚ö° √âTAPE 7: OPTIMISATION - PROJECTION\n",
      "============================================================\n",
      "\n",
      "üìä CAS A: Join puis projection (projection tardive)\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Plan Spark (CAS A):\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (16)\n",
      "+- HashAggregate (15)\n",
      "   +- Exchange (14)\n",
      "      +- HashAggregate (13)\n",
      "         +- Project (12)\n",
      "            +- BroadcastHashJoin Inner BuildRight (11)\n",
      "               :- Project (7)\n",
      "               :  +- BroadcastHashJoin Inner BuildLeft (6)\n",
      "               :     :- BroadcastExchange (3)\n",
      "               :     :  +- Filter (2)\n",
      "               :     :     +- Scan csv  (1)\n",
      "               :     +- Filter (5)\n",
      "               :        +- Scan csv  (4)\n",
      "               +- BroadcastExchange (10)\n",
      "                  +- Filter (9)\n",
      "                     +- Scan csv  (8)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [2]: [order_id#13, order_date#15]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_orders.csv]\n",
      "PushedFilters: [IsNotNull(order_id)]\n",
      "ReadSchema: struct<order_id:int,order_date:timestamp>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [order_id#13, order_date#15]\n",
      "Condition : isnotnull(order_id#13)\n",
      "\n",
      "(3) BroadcastExchange\n",
      "Input [2]: [order_id#13, order_date#15]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2675]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [3]: [order_id#17, product_id#18, quantity#19]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_order_items.csv]\n",
      "PushedFilters: [IsNotNull(order_id), IsNotNull(product_id)]\n",
      "ReadSchema: struct<order_id:int,product_id:int,quantity:int>\n",
      "\n",
      "(5) Filter\n",
      "Input [3]: [order_id#17, product_id#18, quantity#19]\n",
      "Condition : (isnotnull(order_id#17) AND isnotnull(product_id#18))\n",
      "\n",
      "(6) BroadcastHashJoin\n",
      "Left keys [1]: [order_id#13]\n",
      "Right keys [1]: [order_id#17]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(7) Project\n",
      "Output [3]: [order_date#15, product_id#18, quantity#19]\n",
      "Input [5]: [order_id#13, order_date#15, order_id#17, product_id#18, quantity#19]\n",
      "\n",
      "(8) Scan csv \n",
      "Output [2]: [product_id#8, price#12]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_products.csv]\n",
      "PushedFilters: [IsNotNull(product_id)]\n",
      "ReadSchema: struct<product_id:int,price:double>\n",
      "\n",
      "(9) Filter\n",
      "Input [2]: [product_id#8, price#12]\n",
      "Condition : isnotnull(product_id#8)\n",
      "\n",
      "(10) BroadcastExchange\n",
      "Input [2]: [product_id#8, price#12]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2679]\n",
      "\n",
      "(11) BroadcastHashJoin\n",
      "Left keys [1]: [product_id#18]\n",
      "Right keys [1]: [product_id#8]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(12) Project\n",
      "Output [3]: [quantity#19, price#12, cast(order_date#15 as date) AS _groupingexpression#558]\n",
      "Input [5]: [order_date#15, product_id#18, quantity#19, product_id#8, price#12]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [3]: [quantity#19, price#12, _groupingexpression#558]\n",
      "Keys [1]: [_groupingexpression#558]\n",
      "Functions [1]: [partial_sum((cast(quantity#19 as double) * price#12))]\n",
      "Aggregate Attributes [1]: [sum#559]\n",
      "Results [2]: [_groupingexpression#558, sum#560]\n",
      "\n",
      "(14) Exchange\n",
      "Input [2]: [_groupingexpression#558, sum#560]\n",
      "Arguments: hashpartitioning(_groupingexpression#558, 200), ENSURE_REQUIREMENTS, [plan_id=2684]\n",
      "\n",
      "(15) HashAggregate\n",
      "Input [2]: [_groupingexpression#558, sum#560]\n",
      "Keys [1]: [_groupingexpression#558]\n",
      "Functions [1]: [sum((cast(quantity#19 as double) * price#12))]\n",
      "Aggregate Attributes [1]: [sum((cast(quantity#19 as double) * price#12))#557]\n",
      "Results [2]: [_groupingexpression#558 AS d#544, sum((cast(quantity#19 as double) * price#12))#557 AS gmv#545]\n",
      "\n",
      "(16) AdaptiveSparkPlan\n",
      "Output [2]: [d#544, gmv#545]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "\n",
      "üìà R√©sultats CAS A:\n",
      "   Lignes: 37\n",
      "   Temps: 1.089s\n",
      "+----------+------------------+\n",
      "|         d|               gmv|\n",
      "+----------+------------------+\n",
      "|2024-08-27|           3909.94|\n",
      "|2024-10-24|5539.9400000000005|\n",
      "|2024-11-02|           2324.92|\n",
      "|2024-09-10|           5259.94|\n",
      "|2024-08-05|           1399.98|\n",
      "|2024-08-29|19749.789999999997|\n",
      "|2024-08-07|             39.99|\n",
      "|2024-11-05|15599.880000000001|\n",
      "|2024-06-23|16699.910000000003|\n",
      "|2024-08-15|           3559.91|\n",
      "|2024-09-12|            949.97|\n",
      "|2024-11-07|           3569.92|\n",
      "|2024-09-25|13679.779999999999|\n",
      "|2024-10-01|           1399.96|\n",
      "|2024-09-21|           1859.95|\n",
      "|2024-11-11|            819.94|\n",
      "|2024-10-15|           6649.87|\n",
      "|2024-09-09|            699.99|\n",
      "|2024-10-28|2099.9700000000003|\n",
      "|2024-09-05|          12979.89|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "üìä CAS B: Projection puis join (projection pr√©coce)\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Plan Spark (CAS B):\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (16)\n",
      "+- HashAggregate (15)\n",
      "   +- Exchange (14)\n",
      "      +- HashAggregate (13)\n",
      "         +- Project (12)\n",
      "            +- BroadcastHashJoin Inner BuildRight (11)\n",
      "               :- Project (7)\n",
      "               :  +- BroadcastHashJoin Inner BuildLeft (6)\n",
      "               :     :- BroadcastExchange (3)\n",
      "               :     :  +- Filter (2)\n",
      "               :     :     +- Scan csv  (1)\n",
      "               :     +- Filter (5)\n",
      "               :        +- Scan csv  (4)\n",
      "               +- BroadcastExchange (10)\n",
      "                  +- Filter (9)\n",
      "                     +- Scan csv  (8)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [2]: [order_id#13, order_date#15]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_orders.csv]\n",
      "PushedFilters: [IsNotNull(order_id)]\n",
      "ReadSchema: struct<order_id:int,order_date:timestamp>\n",
      "\n",
      "(2) Filter\n",
      "Input [2]: [order_id#13, order_date#15]\n",
      "Condition : isnotnull(order_id#13)\n",
      "\n",
      "(3) BroadcastExchange\n",
      "Input [2]: [order_id#13, order_date#15]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=3299]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [3]: [order_id#17, product_id#18, quantity#19]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_order_items.csv]\n",
      "PushedFilters: [IsNotNull(order_id), IsNotNull(product_id)]\n",
      "ReadSchema: struct<order_id:int,product_id:int,quantity:int>\n",
      "\n",
      "(5) Filter\n",
      "Input [3]: [order_id#17, product_id#18, quantity#19]\n",
      "Condition : (isnotnull(order_id#17) AND isnotnull(product_id#18))\n",
      "\n",
      "(6) BroadcastHashJoin\n",
      "Left keys [1]: [order_id#13]\n",
      "Right keys [1]: [order_id#17]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(7) Project\n",
      "Output [3]: [order_date#15, product_id#18, quantity#19]\n",
      "Input [5]: [order_id#13, order_date#15, order_id#17, product_id#18, quantity#19]\n",
      "\n",
      "(8) Scan csv \n",
      "Output [2]: [product_id#8, price#12]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/home/bibawandaogo/data engineering 1/data/lab2_products.csv]\n",
      "PushedFilters: [IsNotNull(product_id)]\n",
      "ReadSchema: struct<product_id:int,price:double>\n",
      "\n",
      "(9) Filter\n",
      "Input [2]: [product_id#8, price#12]\n",
      "Condition : isnotnull(product_id#8)\n",
      "\n",
      "(10) BroadcastExchange\n",
      "Input [2]: [product_id#8, price#12]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=3303]\n",
      "\n",
      "(11) BroadcastHashJoin\n",
      "Left keys [1]: [product_id#18]\n",
      "Right keys [1]: [product_id#8]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(12) Project\n",
      "Output [3]: [quantity#19, price#12, cast(order_date#15 as date) AS _groupingexpression#599]\n",
      "Input [5]: [order_date#15, product_id#18, quantity#19, product_id#8, price#12]\n",
      "\n",
      "(13) HashAggregate\n",
      "Input [3]: [quantity#19, price#12, _groupingexpression#599]\n",
      "Keys [1]: [_groupingexpression#599]\n",
      "Functions [1]: [partial_sum((cast(quantity#19 as double) * price#12))]\n",
      "Aggregate Attributes [1]: [sum#600]\n",
      "Results [2]: [_groupingexpression#599, sum#601]\n",
      "\n",
      "(14) Exchange\n",
      "Input [2]: [_groupingexpression#599, sum#601]\n",
      "Arguments: hashpartitioning(_groupingexpression#599, 200), ENSURE_REQUIREMENTS, [plan_id=3308]\n",
      "\n",
      "(15) HashAggregate\n",
      "Input [2]: [_groupingexpression#599, sum#601]\n",
      "Keys [1]: [_groupingexpression#599]\n",
      "Functions [1]: [sum((cast(quantity#19 as double) * price#12))]\n",
      "Aggregate Attributes [1]: [sum((cast(quantity#19 as double) * price#12))#598]\n",
      "Results [2]: [_groupingexpression#599 AS d#591, sum((cast(quantity#19 as double) * price#12))#598 AS gmv#592]\n",
      "\n",
      "(16) AdaptiveSparkPlan\n",
      "Output [2]: [d#591, gmv#592]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "\n",
      "üìà R√©sultats CAS B:\n",
      "   Lignes: 37\n",
      "   Temps: 0.764s\n",
      "+----------+------------------+\n",
      "|         d|               gmv|\n",
      "+----------+------------------+\n",
      "|2024-08-27|           3909.94|\n",
      "|2024-10-24|5539.9400000000005|\n",
      "|2024-11-02|           2324.92|\n",
      "|2024-09-10|           5259.94|\n",
      "|2024-08-05|           1399.98|\n",
      "|2024-08-29|19749.789999999997|\n",
      "|2024-08-07|             39.99|\n",
      "|2024-11-05|15599.880000000001|\n",
      "|2024-06-23|16699.910000000003|\n",
      "|2024-08-15|           3559.91|\n",
      "|2024-09-12|            949.97|\n",
      "|2024-11-07|           3569.92|\n",
      "|2024-09-25|13679.779999999999|\n",
      "|2024-10-01|           1399.96|\n",
      "|2024-09-21|           1859.95|\n",
      "|2024-11-11|            819.94|\n",
      "|2024-10-15|           6649.87|\n",
      "|2024-09-09|            699.99|\n",
      "|2024-10-28|2099.9700000000003|\n",
      "|2024-09-05|          12979.89|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "============================================================\n",
      "üìä COMPARAISON CAS A vs CAS B\n",
      "============================================================\n",
      "\n",
      "Proj Tardive (A): 1.089s\n",
      "Proj Pr√©coce (B): 0.764s\n",
      "Am√©lioration:     +29.8%\n",
      "\n",
      "‚úÖ Projection PR√âCOCE est 1.42x plus rapide!\n",
      "\n",
      "‚úÖ M√©triques sauvegard√©es dans proof/projection_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ö° √âTAPE 7: OPTIMISATION - PROJECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import time\n",
    "\n",
    "# ========== CAS A: JOIN PUIS PROJECT (TARDIF) ==========\n",
    "print(\"\\nüìä CAS A: Join puis projection (projection tardive)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "start_a = time.time()\n",
    "\n",
    "df_a = (orders.join(order_items, \"order_id\")\n",
    "            .join(products, \"product_id\")\n",
    "            .groupBy(F.to_date(\"order_date\").alias(\"d\"))\n",
    "            .agg(F.sum(F.col(\"quantity\") * F.col(\"price\")).alias(\"gmv\")))\n",
    "\n",
    "print(\"\\nüîç Plan Spark (CAS A):\\n\")\n",
    "df_a.explain(\"formatted\")\n",
    "\n",
    "count_a = df_a.count()\n",
    "time_a = time.time() - start_a\n",
    "\n",
    "print(f\"\\nüìà R√©sultats CAS A:\")\n",
    "print(f\"   Lignes: {count_a}\")\n",
    "print(f\"   Temps: {time_a:.3f}s\")\n",
    "\n",
    "df_a.show()\n",
    "\n",
    "# Sauvegarde le plan\n",
    "with open(\"proof/plan_case_a_late_projection.txt\", \"w\") as f:\n",
    "    f.write(f\"=== CAS A: PROJECTION TARDIVE ===\\n\")\n",
    "    f.write(f\"Timestamp: {_dt.now()}\\n\")\n",
    "    f.write(f\"Dur√©e: {time_a:.3f}s\\n\\n\")\n",
    "    f.write(df_a._jdf.queryExecution().executedPlan().toString())\n",
    "\n",
    "# ========== CAS B: PROJECT PUIS JOIN (PR√âCOCE) ==========\n",
    "print(\"\\nüìä CAS B: Projection puis join (projection pr√©coce)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "start_b = time.time()\n",
    "\n",
    "df_b = (orders.select(\"order_id\", \"order_date\")\n",
    "            .join(order_items.select(\"order_id\", \"product_id\", \"quantity\"), \"order_id\")\n",
    "            .join(products.select(\"product_id\", \"price\"), \"product_id\")\n",
    "            .groupBy(F.to_date(\"order_date\").alias(\"d\"))\n",
    "            .agg(F.sum(F.col(\"quantity\") * F.col(\"price\")).alias(\"gmv\")))\n",
    "\n",
    "print(\"\\nüîç Plan Spark (CAS B):\\n\")\n",
    "df_b.explain(\"formatted\")\n",
    "\n",
    "count_b = df_b.count()\n",
    "time_b = time.time() - start_b\n",
    "\n",
    "print(f\"\\nüìà R√©sultats CAS B:\")\n",
    "print(f\"   Lignes: {count_b}\")\n",
    "print(f\"   Temps: {time_b:.3f}s\")\n",
    "\n",
    "df_b.show()\n",
    "\n",
    "# Sauvegarde le plan\n",
    "with open(\"proof/plan_case_b_early_projection.txt\", \"w\") as f:\n",
    "    f.write(f\"=== CAS B: PROJECTION PR√âCOCE ===\\n\")\n",
    "    f.write(f\"Timestamp: {_dt.now()}\\n\")\n",
    "    f.write(f\"Dur√©e: {time_b:.3f}s\\n\\n\")\n",
    "    f.write(df_b._jdf.queryExecution().executedPlan().toString())\n",
    "\n",
    "# ========== COMPARAISON ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARAISON CAS A vs CAS B\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "improvement = ((time_a - time_b) / time_a * 100) if time_a > 0 else 0\n",
    "\n",
    "print(f\"\\nProj Tardive (A): {time_a:.3f}s\")\n",
    "print(f\"Proj Pr√©coce (B): {time_b:.3f}s\")\n",
    "print(f\"Am√©lioration:     {improvement:+.1f}%\")\n",
    "\n",
    "if time_b < time_a:\n",
    "    print(f\"\\n‚úÖ Projection PR√âCOCE est {time_a/time_b:.2f}x plus rapide!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Les performances sont similaires (small dataset)\")\n",
    "\n",
    "# Sauvegarde les m√©triques\n",
    "with open(\"proof/projection_comparison.csv\", \"w\") as f:\n",
    "    f.write(\"Cas,Approche,Temps(s),Lignes,Am√©lioration(%)\\n\")\n",
    "    f.write(f\"A,Projection Tardive,{time_a:.3f},{count_a},{0:.1f}\\n\")\n",
    "    f.write(f\"B,Projection Pr√©coce,{time_b:.3f},{count_b},{improvement:.1f}\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ M√©triques sauvegard√©es dans proof/projection_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df8f9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìã √âTAPE 8: R√âSUM√â FINAL\n",
      "============================================================\n",
      "\n",
      "üìä M√âTRIQUES CL√âS:\n",
      "\n",
      "   Timestamp                : 2025-12-09 20:51:27.883443\n",
      "   Spark Version            : 4.0.1\n",
      "   Total Customers          : 10\n",
      "   Total Brands             : 5\n",
      "   Total Categories         : 5\n",
      "   Total Products           : 20\n",
      "   Total Dates              : 45\n",
      "   Total Orders (Facts)     : 100\n",
      "   Total GMV                : $196,872.05\n",
      "   Avg Order Value          : $1,968.72\n",
      "\n",
      "‚úÖ M√©triques sauvegard√©es dans proof/lab2_metrics_final.csv\n",
      "\n",
      "============================================================\n",
      "üìÅ FICHIERS DE PREUVE G√âN√âR√âS:\n",
      "============================================================\n",
      "   1. proof/date_dimension_summary.csv (92 bytes)\n",
      "   2. proof/dimensions_summary.csv (92 bytes)\n",
      "   3. proof/fact_sales_summary.csv (102 bytes)\n",
      "   4. proof/ingestion_summary.csv (130 bytes)\n",
      "   5. proof/lab2_metrics_final.csv (249 bytes)\n",
      "   6. proof/plan_case_a_late_projection.txt (2,462 bytes)\n",
      "   7. proof/plan_case_b_early_projection.txt (2,463 bytes)\n",
      "   8. proof/plan_df.txt (1,535 bytes)\n",
      "   9. proof/plan_fact_join.txt (3,221 bytes)\n",
      "   10. proof/plan_formatted.txt (715 bytes)\n",
      "   11. proof/plan_ingest.txt (1,317 bytes)\n",
      "   12. proof/plan_rdd.txt (883 bytes)\n",
      "   13. proof/projection_comparison.csv (116 bytes)\n",
      "\n",
      "============================================================\n",
      "‚úÖ Session Spark arr√™t√©e\n",
      "\n",
      "üéâ LAB 2 PRACTICE TERMIN√â AVEC SUCC√àS!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã √âTAPE 8: R√âSUM√â FINAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_metrics = {\n",
    "    \"Timestamp\": str(_dt.now()),\n",
    "    \"Spark Version\": spark.version,\n",
    "    \"Total Customers\": dim_customer.count(),\n",
    "    \"Total Brands\": dim_brand.count(),\n",
    "    \"Total Categories\": dim_category.count(),\n",
    "    \"Total Products\": dim_product.count(),\n",
    "    \"Total Dates\": dim_date.count(),\n",
    "    \"Total Orders (Facts)\": df_fact.count(),\n",
    "    \"Total GMV\": fact_stats['total_gmv'],\n",
    "    \"Avg Order Value\": fact_stats['avg_order_value'],\n",
    "}\n",
    "\n",
    "# Affiche le r√©sum√©\n",
    "print(\"\\nüìä M√âTRIQUES CL√âS:\\n\")\n",
    "for key, value in summary_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   {key:25s}: ${value:,.2f}\")\n",
    "    else:\n",
    "        print(f\"   {key:25s}: {value}\")\n",
    "\n",
    "# Sauvegarde dans CSV\n",
    "with open(\"proof/lab2_metrics_final.csv\", \"w\") as f:\n",
    "    f.write(\"M√©trique,Valeur\\n\")\n",
    "    for key, value in summary_metrics.items():\n",
    "        f.write(f\"{key},{value}\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ M√©triques sauvegard√©es dans proof/lab2_metrics_final.csv\")\n",
    "\n",
    "# Liste tous les fichiers de preuve\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÅ FICHIERS DE PREUVE G√âN√âR√âS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "proof_files = os.listdir(\"proof\")\n",
    "for i, file in enumerate(sorted(proof_files), 1):\n",
    "    size = os.path.getsize(f\"proof/{file}\")\n",
    "    print(f\"   {i}. proof/{file} ({size:,} bytes)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Arr√™te Spark\n",
    "spark.stop()\n",
    "print(\"‚úÖ Session Spark arr√™t√©e\")\n",
    "print(\"\\nüéâ LAB 2 PRACTICE TERMIN√â AVEC SUCC√àS!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
