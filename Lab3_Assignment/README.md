# Lab3_Assignment: Data Engineering with Apache Spark

Analyse complÃ¨te de donnÃ©es e-commerce avec **Spark SQL**, **DataFrames** et **RDDs**.

## ğŸ“‹ Contenu du Lab

### Questions Q1-Q7
- **Q1**: Purchase price for specific session
- **Q2**: Products sold by brand "sokolov"
- **Q3**: Average purchase price by brand (Ferre)
- **Q4**: Average number of events per user
- **Q5**: Top 10 product-brand pairs by revenue
- **Q6**: Events by hour of day (with visualization)
- **Q7**: Average purchase price by brand > $10K (with bar chart)

### Section 5: RDD Operations
- Version 1: `groupByKey()` (naive algorithm)
- Version 3: `reduceByKey()` (optimized algorithm)
- Comparaison des performances

### Section 6: Join Implementations
- **Shuffle Join** (reduce-side join)
- **Replicated Hash Join** (broadcast join)

### Section 7: Performance Analysis
- Comparaison J1 (Shuffle) vs J2 (Hash: brands as R) vs J3 (Hash: products as R)
- Analyse des temps d'exÃ©cution

## ğŸš€ Setup

### PrÃ©requis
- Apache Spark 4.0.1+
- Python 3.8+
- Jupyter Notebook

### Installation

```bash
# Cloner le repo
git clone https://github.com/bibatou2004/DataEng_Labs.git
cd Lab3_Assignment

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### TÃ©lÃ©charger les donnÃ©es

```bash
# TÃ©lÃ©charger depuis Dropbox
wget https://www.dropbox.com/scl/fi/7012u693u06dgj95mgq2a/retail_dw_20250826.tar.gz

# Extraire
tar -xzf retail_dw_20250826.tar.gz -C data/input/
```

### Lancer le Notebook

```bash
jupyter notebook notebooks/Lab3_Assignment.ipynb
```

## ğŸ“Š RÃ©sultats ClÃ©s

| Question | RÃ©sultat | Type |
|----------|----------|------|
| Q1 | Purchase Price | SQL + DataFrame |
| Q2 | Num Products | SQL + DataFrame |
| Q3 | Avg Price | SQL + DataFrame |
| Q4 | Avg Events/User | SQL + DataFrame |
| Q5 | Top 10 Pairs | SQL + DataFrame |
| Q6 | Events by Hour | SQL + DataFrame + Plot |
| Q7 | Avg Price > 10K | SQL + DataFrame + Bar Chart |

## âš¡ Performance Comparison

### RDD Operations
- **V1 (groupByKey)**: Plus lent, shuffle complet
- **V3 (reduceByKey)**: Plus rapide, agrÃ©gation prÃ©coce

### Join Operations
- **J1 (Shuffle Join)**: Lent, shuffle global
- **J2 (Hash: R=brands)**: Moyen, broadcast petit
- **J3 (Hash: R=products)**: Rapide, broadcast grand

## ğŸ“ Structure du Projet

```
Lab3_Assignment/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Lab3_Assignment.ipynb
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/         (parquet files)
â”‚   â””â”€â”€ output/        (rÃ©sultats)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ spark_config.py
â”‚   â”œâ”€â”€ joins.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ RESULTS.md
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

## ğŸ“ Notes Importantes

- Les fichiers parquet ne sont pas pushÃ©s (trop volumineux)
- Les visualisations matplotlib sont incluses dans le notebook
- Tous les rÃ©sultats sont arrondis Ã  2 dÃ©cimales

## ğŸ‘¤ Auteur

Biba Wanda Ogo

## ğŸ“„ Licence

MIT License
