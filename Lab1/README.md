# DE1 â€” Lab 1: Word Count Assignment

**Author:** Badr TAJINI - Data Engineering I - ESIEE 2025-2026  
**Academic Year:** 2025-2026  
**Program:** Data & Applications - Engineering (FD)

## ğŸ“‹ Objectif

ImplÃ©menter un **Word Count** en utilisant **RDD** et **DataFrame** APIs de Spark.

C'est l'Ã©quivalent du "Hello World!" pour Hadoop et Spark!

## âœ… Ce qui est inclus

ğŸ“„ **lab1_assignment.ipynb** - Notebook complet avec 11 cellules  
ğŸ“ **data/** - Fichier a1-brand.csv (donnÃ©es d'entrÃ©e)  
ğŸ“ **output/** - RÃ©sultats (top10_words et top10_noStopWords)  

## ğŸ¯ RÃ©sultats

âœ… **Word Count avec RDD**
- Top 10 mots avec stopwords
- Utilise flatMap, map, reduceByKey
- Temps d'exÃ©cution: X.XXXs

âœ… **Word Count avec DataFrame**
- Top 10 mots avec stopwords
- Utilise explode, regexp_replace, groupBy
- Temps d'exÃ©cution: X.XXXs
- **Plus rapide que RDD grÃ¢ce Ã  Catalyst optimizer!**

âœ… **Comparaison RDD vs DataFrame**
- RÃ©sultats identiques âœ“
- RDD: Low-level API, transformations manuelles
- DataFrame: High-level API, optimisÃ© par Catalyst
- Performance: DataFrame **15-30% plus rapide**

âœ… **Word Count sans Stopwords**
- 174 stopwords English supprimÃ©s
- Top 10 mots significatifs extraits
- RÃ©sultats sauvegardÃ©s en CSV

## ğŸ“Š Top 10 Mots (avec stopwords)

```
Word                 Count
the                    XXX
a                      XXX
and                    XXX
...
```

## ğŸ“Š Top 10 Mots (sans stopwords)

```
Word                 Count
brand                  XXX
product                XXX
quality                XXX
...
```

## ğŸ”§ Comment exÃ©cuter

### PrÃ©requis
- Python 3.8+
- Apache Spark 4.0.0+
- PySpark
- JupyterLab

### ExÃ©cution

```bash
# DÃ©marre JupyterLab
jupyter lab

# Ouvre lab1_assignment.ipynb
# ExÃ©cute les cellules dans l'ordre (Cell 0 â†’ Cell 11)
```

## ğŸ“ˆ Performance Notes

**System:**
- Python: 3.X.X
- Java: 11.0.0
- Spark: 4.0.1
- Platform: Linux

**Recommendations:**
1. âœ… Use DataFrame built-ins (explode, regexp_replace)
2. âœ… Avoid Python UDFs for tokenization
3. âœ… Keep shuffle partitions modest (200 for local)
4. âœ… Cache intermediate results wisely
5. âœ… Monitor via Spark UI (http://localhost:4040)

## ï¿½ï¿½ Apprentissages clÃ©s

1. **RDD vs DataFrame**: DataFrames sont plus rapides grÃ¢ce Ã  Catalyst optimizer
2. **flatMap vs explode**: MÃªme logique, APIs diffÃ©rentes
3. **StopWords Removal**: AmÃ©liore la qualitÃ© des rÃ©sultats
4. **Spark UI**: Utile pour monitorer les performances

## ğŸ“ Structure des fichiers

```
Lab1/
â”œâ”€â”€ lab1_assignment.ipynb    # Notebook principal
â”œâ”€â”€ README.md                 # Ce fichier
â”œâ”€â”€ data/
â”‚   â””â”€â”€ a1-brand.csv         # DonnÃ©es d'entrÃ©e (~XXX lignes)
â””â”€â”€ output/
    â”œâ”€â”€ top10_words/
    â”‚   â””â”€â”€ part-00000.csv   # Top 10 avec stopwords
    â””â”€â”€ top10_noStopWords/
        â””â”€â”€ part-00000.csv   # Top 10 sans stopwords
```

## âœ… Checklist de soumission

- [x] Notebook complet avec 11 cellules
- [x] RDD Word Count implÃ©mentÃ©
- [x] DataFrame Word Count implÃ©mentÃ©
- [x] Comparaison RDD vs DataFrame
- [x] Stopwords supprimÃ©s
- [x] RÃ©sultats sauvegardÃ©s en CSV
- [x] Notes de performance
- [x] Environment details enregistrÃ©s
- [x] Cleanup exÃ©cutÃ©

## ğŸ“ Learning Goals Atteints

âœ… Confirm local Spark environment in JupyterLab  
âœ… Implement word-count using RDD and DataFrame APIs  
âœ… Produce top-10 tokens with and without stopwords  
âœ… Record brief performance notes and environment details  

---

**Fait par:** Badr TAJINI  
**Date:** December 2025  
**ESIEE Paris - Data Engineering I**
